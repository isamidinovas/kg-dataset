
# correct
import os
import time
import re
import json
import google.generativeai as genai
import pandas as pd


model = genai.GenerativeModel("gemini-2.0-flash")
AUTO_PROMPT = (
    "–ü—Ä–æ—á—Ç–∏ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –Ω–∏–∂–µ —Ç–µ–∫—Å—Ç –∏ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ —Å–æ–∑–¥–∞–π **–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π, –≥–ª—É–±–æ–∫–∏–π –∏ —Ä–∞–∑–Ω–æ–ø–ª–∞–Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç** "
    "–∏–∑ **8 –ø–∞—Ä '–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç'**, –∫–∞—Å–∞—é—â–∏—Ö—Å—è –∫—ã—Ä–≥—ã–∑—Å–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏, –∫—É–ª—å—Ç—É—Ä—ã, —Ç—Ä–∞–¥–∏—Ü–∏–π –∏ –æ–±—ã—á–∞–µ–≤.\n\n"
    "**–í–∞–∂–Ω–æ:**\n"
    "- –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω—ã **—Å—Ç—Ä–æ–≥–æ –Ω–∞ –∫—ã—Ä–≥—ã–∑—Å–∫–æ–º —è–∑—ã–∫–µ**.\n"
    "- –ö–∞–∂–¥—ã–π **–≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ –º–µ–Ω–µ–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤**.\n"
    "- –ö–∞–∂–¥—ã–π **–æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ –º–µ–Ω–µ–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤**.\n\n"
    "**–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤:**\n"
    "- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ ¬´—Ç–µ–∫—Å—Ç–∫–µ —ã–ª–∞–π—ã–∫¬ª, ¬´—Ç–µ–∫—Å—Ç—Ç–µ –±–µ—Ä–∏–ª–≥–µ–Ω–¥–µ–π¬ª, ¬´—Ç–µ–∫—Å—Ç—Ç–µ¬ª, ¬´—Ç–µ–∫—Å—Ç—Ç–µ–≥–∏¬ª, ¬´—Ç–µ–∫—Å—Ç—Ç–µ –∞–π—Ç—ã–ª–≥–∞–Ω–¥–∞–π¬ª, ¬´–∂–æ–≥–æ—Ä—É–¥–∞–≥—ã –º–∞–∞–ª—ã–º–∞—Ç—Ç–∞—Ä–≥–∞ —Ç–∞—è–Ω—ã–ø¬ª, –∏ —Ç.–¥.\n"
    "- –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω **–Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ —Ç–µ–º–µ**, **–±–µ–∑ –æ—Ç—Å—ã–ª–æ–∫ –Ω–∞ —Ç–µ–∫—Å—Ç**.\n\n"
    "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–æ–ø—Ä–æ—Å–∞–º:**\n"
    "- –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á—ë—Ç–∫–∏–º–∏, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–º–∏, –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã: —Ç–∞—Ä—ã—Ö, –∏–Ω—Å–∞–Ω–¥–∞—Ä, –º–∞–¥–∞–Ω–∏—è—Ç, –∫–∞–∞–¥–∞-—Å–∞–ª—Ç—Ç–∞—Ä –∂.–±.\n"
    "- –ù–µ –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã–µ –∏–ª–∏ –±–∞–Ω–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.\n\n"
    "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç–∞–º:**\n"
    "- –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–æ–≥–∏—á–Ω—ã–º–∏, —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–Ω—ã–º–∏ –∏ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏.\n"
    "- –ü–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∫–ª—é—á–∞–π –º–∏—Å–∞–ª–¥–∞—Ä, –¥–∞—Ç–∞–ª–∞—Ä, –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å–∞–ª—ã—à—Ç—ã—Ä—É—É–ª–∞—Ä.\n\n"
    "**–§–æ—Ä–º–∞—Ç:** –í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON-–º–∞—Å—Å–∏–≤ –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π. –ü—Ä–∏–º–µ—Ä:\n"
    "[\n  {\"question\": \"...\", \"answer\": \"...\"},\n  ...\n]"
)



def split_text_by_paragraphs(text: str, paragraphs_per_chunk: int = 60) -> list[str]:
    paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
    chunks = []

    for i in range(0, len(paragraphs), paragraphs_per_chunk):
        chunk = "\n".join(paragraphs[i:i + paragraphs_per_chunk])
        chunks.append(chunk)

    return chunks


def clean_response(text: str) -> str:
    return re.sub(r"```(?:json)?|```", "", text).strip()


def extract_qa_pairs(text: str) -> list[tuple[str, str]]:
    text = clean_response(text)

    try:
        data = json.loads(text)
        return [(item['question'], item['answer']) for item in data if 'question' in item and 'answer' in item]
    except json.JSONDecodeError:
        print("‚ö†Ô∏è JSON –Ω–µ–≤–∞–ª–∏–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è...")

    pattern = re.compile(
        r'{"question"\s*:\s*"(?P<question>.*?)"\s*,\s*"answer"\s*:\s*"(?P<answer>.*?)"}',
        re.DOTALL
    )

    matches = pattern.findall(text)
    if not matches:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–∞—Ä—ã –≤—Ä—É—á–Ω—É—é.")
    return matches

def main():
    file_path = "data/–ö—ã—Ä–≥—ã–∑–¥—ã–Ω_–∫–æ–ª_”©–Ω”©—Ä—á“Ø–ª“Ø–≥“Ø.txt"
    output_file = "–ö—ã—Ä–≥—ã–∑–¥—ã–Ω_–∫–æ–ª_”©–Ω”©—Ä—á“Ø–ª“Ø–≥“Ø.xlsx"

    if not os.path.exists(file_path):
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    with open(file_path, "r", encoding="utf-8") as f:
        full_text = f.read()

    chunks = split_text_by_paragraphs(full_text, paragraphs_per_chunk=60)
    print(f"‚úÖ –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π –ø–æ 60 –∞–±–∑–∞—Ü–µ–≤")


    data = []
    seen_questions = set()

    for idx, chunk in enumerate(chunks):
        print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ {idx + 1} –∏–∑ {len(chunks)}...")
        full_prompt = f"{AUTO_PROMPT}\n\n–¢–µ–∫—Å—Ç:\n{chunk}"

        try:
            response = model.generate_content(full_prompt)
            cleaned = clean_response(response.text)
            qa_pairs = extract_qa_pairs(cleaned)

            if qa_pairs:
                for q, a in qa_pairs:
                    q = q.strip()
                    a = a.strip()
                    if q in seen_questions:
                        continue
                    seen_questions.add(q)
                    data.append({
                        "–í–æ–ø—Ä–æ—Å": q,
                        "–û—Ç–≤–µ—Ç": a,
                        "–î–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞": len(q),
                        "–î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞": len(a)
                    })
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(qa_pairs)}")
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            with open("errors.txt", "a", encoding="utf-8") as log:
                log.write(f"\n--- –ß–∞—Å—Ç—å {idx+1} ---\n{chunk}\n–û—à–∏–±–∫–∞: {e}\n")

        time.sleep(30)

    if data:
        df = pd.DataFrame(data)
        df.to_excel(output_file, index=False)
        print(f"\nüìÅ Excel-—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")



if __name__ == "__main__":
    main()

